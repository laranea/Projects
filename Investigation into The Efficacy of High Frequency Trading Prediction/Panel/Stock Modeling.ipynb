{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../import.py\n",
    "import quandl\n",
    "quandl.ApiConfig.api_key = 'MBMzvkxtv63KjFEV-tL6'\n",
    "from quandl.errors.quandl_error import NotFoundError\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn import linear_model\n",
    "\n",
    "import ipywidgets as widgets \n",
    "from ipywidgets import  interact, interactive, fixed, interact_manual\n",
    "from IPython.display import display\n",
    "\n",
    "#####################################################################################\n",
    "# From tensorflow includes\n",
    "import math\n",
    "from matplotlib import cm\n",
    "from matplotlib import gridspec\n",
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.data import Dataset\n",
    "\n",
    "\n",
    "# For elongating day \n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow GPU Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22. 28.]\n",
      " [49. 64.]]\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "    c = tf.matmul(a, b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print (sess.run(c))\n",
    "    \n",
    "## Configrirng TF\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "pd.options.display.max_rows =10\n",
    "pd.options.display.float_format = '{:.1f}'.format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up columns name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_list=pd.read_csv(\"../sector_list.csv\")\n",
    "main_col_names= [\n",
    " 'Date',\n",
    " 'Close',\n",
    " 'TotalTradeQuantity',\n",
    " 'Turnover_Lacs',\n",
    " 'Return',   \n",
    " 'DEP_Q',\n",
    " 'DIVSH_Q',\n",
    " 'EBIDT_Q',\n",
    " 'EPS_Q',\n",
    " 'EQCAP_Q',\n",
    " 'ETR_Q',\n",
    " 'FV_Q',\n",
    " 'INT_Q',\n",
    " 'MCAP_Q',\n",
    " 'NP_Q',\n",
    " 'OEXPNS_Q',\n",
    " 'OI_Q',\n",
    " 'OP_Q',\n",
    " 'OPMSH_Q',\n",
    " 'OPSH1Q_Q',\n",
    " 'PBDT_Q',\n",
    " 'PBT_Q',\n",
    " 'REVSH_Q',\n",
    " 'SHARE_Q',\n",
    " 'SR_Q',\n",
    " 'TAX_Q',\n",
    " 'TI_Q',\n",
    " 'monthday',\n",
    " 'month',\n",
    " 'weekday',\n",
    " 'Counter',\n",
    " 'Ticker' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting the sectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "980e1ce3cccb4d36a8eb463df2b79963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "aW50ZXJhY3RpdmUoY2hpbGRyZW49KERyb3Bkb3duKGRlc2NyaXB0aW9uPXUnU2VjdG9yOicsIG9wdGlvbnM9KCdBR1JPX0lOUFVUUycsICdBVVRPTU9CSUxFUycsICdBVVRPX0FOQ0lMTEFSSUXigKY=\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def select_sector(sector_name):\n",
    "    \n",
    "    sector_file_name= \"../Panel/Data/\"+sector_name+\".csv\"\n",
    "    df= pd.read_csv(sector_file_name,header=None, names=main_col_names, dtype=str)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "sector_value=widgets.Dropdown(\n",
    "                            options=s_list['sector'], \n",
    "                            description=\"Sector:\"\n",
    "                            )\n",
    "w=widgets.interactive(select_sector, sector_name=sector_value)\n",
    "display(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=w.result\n",
    "df = df.apply(pd.to_numeric, errors='ignore')\n",
    "df=df[df[\"Ticker\"]==\"NSE/ARIES\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paneling the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = df[\"Ticker\"].unique()\n",
    "minor_axis=df.columns[1:]\n",
    "\n",
    "\n",
    "major_axis=df[\"Date\"].unique()\n",
    "major_axis.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Panels:\n",
    "#### p = Panel\n",
    "* p3 = all exluding last 7\n",
    "* p4 = only last 7\n",
    "* p5 = all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "p3=pd.Panel(major_axis=major_axis[:-7], minor_axis=minor_axis)\n",
    "p4=pd.Panel(major_axis=major_axis[-7:], minor_axis=minor_axis)\n",
    "p5=pd.Panel(major_axis=major_axis, minor_axis=minor_axis)\n",
    "\n",
    "\n",
    "for i in items:\n",
    "    p3_data=df[df[\"Ticker\"]==i]\n",
    "    p3_data.set_index(\"Date\", inplace=True)\n",
    "    p3[i]=p3_data[:\"2018-04-11\"]\n",
    "    p4[i]=p3_data[\"2018-04-12\":]\n",
    "    p5[i]=p3_data\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging All tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "sector_name=w.kwargs[\"sector_name\"]\n",
    "\n",
    "p3_file_name= \"Slices/p3_\"+sector_name+\".csv\"\n",
    "p4_file_name= \"Slices/p4_\"+sector_name+\".csv\"\n",
    "p5_file_name= \"Slices/p5_\"+sector_name+\".csv\"\n",
    "\n",
    "with open(p3_file_name, 'w') as f:\n",
    "    for item in p3.items:\n",
    "        p3[item].to_csv(f, header=False)\n",
    "\n",
    "        \n",
    "with open(p4_file_name, 'w') as g:\n",
    "    for item in p5.items:\n",
    "        p4[item].to_csv(g, header=False)\n",
    "\n",
    "\n",
    "with open(p5_file_name, 'w') as h:\n",
    "    for item in p5.items:\n",
    "        p5[item].to_csv(h, header=False)\n",
    "        \n",
    "d3=pd.read_csv(p3_file_name, names=main_col_names )\n",
    "d4=pd.read_csv(p4_file_name, names=main_col_names )\n",
    "d5=pd.read_csv(p5_file_name, names=main_col_names )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making data sane\n",
    "### 1. Normalizing all data dataset \n",
    "### 2. Hot encoding columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Normalizing all data dataset \n",
    "hot_cols= [\n",
    " 'monthday',\n",
    " 'month',\n",
    " 'weekday',\n",
    " 'Counter']\n",
    "\n",
    "# cols_to_normalize=set(p3.minor_axis) - set(hot_cols) - set([\"Ticker\"]) \n",
    "cols_to_normalize=set(d5.columns) - set(hot_cols) - set([\"Ticker\", \"Date\"]) \n",
    "\n",
    "\n",
    "def df_normalize(df,base_df,cols):\n",
    "    for col in cols:\n",
    "        max_v=base_df[col].max()\n",
    "        min_v=base_df[col].min()\n",
    "        delta=max_v-min_v\n",
    "        \n",
    "        if abs(max_v) and abs (min_v): \n",
    "            df[col]=df[col].apply(       lambda x: float(     1*( (x-min_v)/delta )           )   )\n",
    "        else:\n",
    "            pass\n",
    "    return df\n",
    "\n",
    "\n",
    "def df_normalize_2(df,base_df,cols):\n",
    "    for col in cols:\n",
    "        mean_v=base_df[col].mean()\n",
    "        std_dv=base_df[col].std()\n",
    "        \n",
    "        df[col]=df[col].apply(  lambda x: float((   1*(x-mean_v)/std_dv )           )   )\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['EQCAP_Q', 'TotalTradeQuantity', 'ETR_Q', 'MCAP_Q', 'Return', 'OPMSH_Q', 'Turnover_Lacs', 'OPSH1Q_Q', 'DIVSH_Q', 'NP_Q', 'EPS_Q', 'OI_Q', 'INT_Q', 'SR_Q', 'OEXPNS_Q', 'Close', 'PBT_Q', 'TAX_Q', 'PBDT_Q', 'FV_Q', 'OP_Q', 'DEP_Q', 'EBIDT_Q', 'SHARE_Q', 'REVSH_Q', 'TI_Q'])\n"
     ]
    }
   ],
   "source": [
    "print cols_to_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "d3n=d3.copy()\n",
    "d4n=d4.copy()\n",
    "d5n=d5.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>TotalTradeQuantity</th>\n",
       "      <th>Turnover_Lacs</th>\n",
       "      <th>Return</th>\n",
       "      <th>DEP_Q</th>\n",
       "      <th>DIVSH_Q</th>\n",
       "      <th>EBIDT_Q</th>\n",
       "      <th>EPS_Q</th>\n",
       "      <th>EQCAP_Q</th>\n",
       "      <th>...</th>\n",
       "      <th>REVSH_Q</th>\n",
       "      <th>SHARE_Q</th>\n",
       "      <th>SR_Q</th>\n",
       "      <th>TAX_Q</th>\n",
       "      <th>TI_Q</th>\n",
       "      <th>monthday</th>\n",
       "      <th>month</th>\n",
       "      <th>weekday</th>\n",
       "      <th>Counter</th>\n",
       "      <th>Ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-09-30</td>\n",
       "      <td>60.9</td>\n",
       "      <td>283315.5</td>\n",
       "      <td>147.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20.2</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>57.6</td>\n",
       "      <td>12.4</td>\n",
       "      <td>59.2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NSE/ARIES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-10-01</td>\n",
       "      <td>62.9</td>\n",
       "      <td>392948.0</td>\n",
       "      <td>238.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20.1</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>57.6</td>\n",
       "      <td>12.4</td>\n",
       "      <td>59.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NSE/ARIES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-10-02</td>\n",
       "      <td>65.8</td>\n",
       "      <td>502580.8</td>\n",
       "      <td>329.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>43.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>57.5</td>\n",
       "      <td>12.3</td>\n",
       "      <td>59.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>NSE/ARIES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-10-03</td>\n",
       "      <td>69.7</td>\n",
       "      <td>612214.0</td>\n",
       "      <td>421.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>19.9</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>43.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>57.4</td>\n",
       "      <td>12.2</td>\n",
       "      <td>59.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>NSE/ARIES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-10-04</td>\n",
       "      <td>69.8</td>\n",
       "      <td>200297.0</td>\n",
       "      <td>143.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>19.8</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>43.8</td>\n",
       "      <td>1.3</td>\n",
       "      <td>57.4</td>\n",
       "      <td>12.1</td>\n",
       "      <td>58.9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>NSE/ARIES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Close  TotalTradeQuantity  Turnover_Lacs  Return  DEP_Q  \\\n",
       "0  2012-09-30   60.9            283315.5          147.1     0.0    0.4   \n",
       "1  2012-10-01   62.9            392948.0          238.4     0.2    0.4   \n",
       "2  2012-10-02   65.8            502580.8          329.8     0.0    0.4   \n",
       "3  2012-10-03   69.7            612214.0          421.3     0.1    0.4   \n",
       "4  2012-10-04   69.8            200297.0          143.6     0.0    0.4   \n",
       "\n",
       "   DIVSH_Q  EBIDT_Q  EPS_Q  EQCAP_Q    ...      REVSH_Q  SHARE_Q  SR_Q  TAX_Q  \\\n",
       "0      0.3     20.2   -0.3     13.0    ...         44.0      1.3  57.6   12.4   \n",
       "1      0.3     20.1   -0.3     13.0    ...         44.0      1.3  57.6   12.4   \n",
       "2      0.3     20.0   -0.3     13.0    ...         43.9      1.3  57.5   12.3   \n",
       "3      0.3     19.9   -0.3     13.0    ...         43.9      1.3  57.4   12.2   \n",
       "4      0.3     19.8   -0.3     13.0    ...         43.8      1.3  57.4   12.1   \n",
       "\n",
       "   TI_Q  monthday  month  weekday  Counter     Ticker  \n",
       "0  59.2      30.0    9.0      7.0        1  NSE/ARIES  \n",
       "1  59.1       1.0   10.0      1.0        2  NSE/ARIES  \n",
       "2  59.1       2.0   10.0      2.0        3  NSE/ARIES  \n",
       "3  59.0       3.0   10.0      3.0        4  NSE/ARIES  \n",
       "4  58.9       4.0   10.0      4.0        5  NSE/ARIES  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_normalize(d3n,d5,cols_to_normalize)\n",
    "df_normalize(d4n,d5,cols_to_normalize)\n",
    "df_normalize(d5n,d5,cols_to_normalize)\n",
    "\n",
    "d5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy=pd.get_dummies(d3n, columns = hot_cols)\n",
    "d3n[dummy.columns]=dummy\n",
    "\n",
    "dummy=pd.get_dummies(d4n, columns = hot_cols)\n",
    "d4n[dummy.columns]=dummy\n",
    "\n",
    "dummy=pd.get_dummies(d5n, columns = hot_cols)\n",
    "d5n[dummy.columns]=dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>TotalTradeQuantity</th>\n",
       "      <th>Turnover_Lacs</th>\n",
       "      <th>Return</th>\n",
       "      <th>DEP_Q</th>\n",
       "      <th>DIVSH_Q</th>\n",
       "      <th>EBIDT_Q</th>\n",
       "      <th>EPS_Q</th>\n",
       "      <th>EQCAP_Q</th>\n",
       "      <th>ETR_Q</th>\n",
       "      <th>...</th>\n",
       "      <th>REVSH_Q</th>\n",
       "      <th>SHARE_Q</th>\n",
       "      <th>SR_Q</th>\n",
       "      <th>TAX_Q</th>\n",
       "      <th>TI_Q</th>\n",
       "      <th>monthday</th>\n",
       "      <th>month</th>\n",
       "      <th>weekday</th>\n",
       "      <th>Counter</th>\n",
       "      <th>Ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-09-30</th>\n",
       "      <td>60.9</td>\n",
       "      <td>283315.5</td>\n",
       "      <td>147.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20.2</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>57.6</td>\n",
       "      <td>12.4</td>\n",
       "      <td>59.2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NSE/ARIES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-01</th>\n",
       "      <td>62.9</td>\n",
       "      <td>392948.0</td>\n",
       "      <td>238.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20.1</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>57.6</td>\n",
       "      <td>12.4</td>\n",
       "      <td>59.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NSE/ARIES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-02</th>\n",
       "      <td>65.8</td>\n",
       "      <td>502580.8</td>\n",
       "      <td>329.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>...</td>\n",
       "      <td>43.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>57.5</td>\n",
       "      <td>12.3</td>\n",
       "      <td>59.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>NSE/ARIES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-03</th>\n",
       "      <td>69.7</td>\n",
       "      <td>612214.0</td>\n",
       "      <td>421.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>19.9</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>...</td>\n",
       "      <td>43.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>57.4</td>\n",
       "      <td>12.2</td>\n",
       "      <td>59.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>NSE/ARIES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-04</th>\n",
       "      <td>69.8</td>\n",
       "      <td>200297.0</td>\n",
       "      <td>143.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>19.8</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>...</td>\n",
       "      <td>43.8</td>\n",
       "      <td>1.3</td>\n",
       "      <td>57.4</td>\n",
       "      <td>12.1</td>\n",
       "      <td>58.9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>NSE/ARIES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-14</th>\n",
       "      <td>197.2</td>\n",
       "      <td>15900.0</td>\n",
       "      <td>32.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>16.5</td>\n",
       "      <td>7.3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>65.8</td>\n",
       "      <td>1.3</td>\n",
       "      <td>84.8</td>\n",
       "      <td>6.2</td>\n",
       "      <td>84.6</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>104</td>\n",
       "      <td>NSE/ARIES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-15</th>\n",
       "      <td>195.0</td>\n",
       "      <td>13612.9</td>\n",
       "      <td>27.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>16.5</td>\n",
       "      <td>7.3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>65.8</td>\n",
       "      <td>1.3</td>\n",
       "      <td>84.8</td>\n",
       "      <td>6.2</td>\n",
       "      <td>84.6</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>105</td>\n",
       "      <td>NSE/ARIES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-16</th>\n",
       "      <td>192.8</td>\n",
       "      <td>11325.9</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>16.5</td>\n",
       "      <td>7.3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>65.8</td>\n",
       "      <td>1.3</td>\n",
       "      <td>84.8</td>\n",
       "      <td>6.2</td>\n",
       "      <td>84.6</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>106</td>\n",
       "      <td>NSE/ARIES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-17</th>\n",
       "      <td>190.5</td>\n",
       "      <td>9038.9</td>\n",
       "      <td>18.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>16.5</td>\n",
       "      <td>7.3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>65.8</td>\n",
       "      <td>1.3</td>\n",
       "      <td>84.8</td>\n",
       "      <td>6.3</td>\n",
       "      <td>84.6</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>107</td>\n",
       "      <td>NSE/ARIES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-18</th>\n",
       "      <td>188.3</td>\n",
       "      <td>6751.9</td>\n",
       "      <td>13.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>16.5</td>\n",
       "      <td>7.3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>65.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>84.8</td>\n",
       "      <td>6.3</td>\n",
       "      <td>84.6</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>108</td>\n",
       "      <td>NSE/ARIES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2027 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Close TotalTradeQuantity Turnover_Lacs Return DEP_Q DIVSH_Q  \\\n",
       "2012-09-30  60.9           283315.5         147.1    0.0   0.4     0.3   \n",
       "2012-10-01  62.9           392948.0         238.4    0.2   0.4     0.3   \n",
       "2012-10-02  65.8           502580.8         329.8    0.0   0.4     0.3   \n",
       "2012-10-03  69.7           612214.0         421.3    0.1   0.4     0.3   \n",
       "2012-10-04  69.8           200297.0         143.6    0.0   0.4     0.3   \n",
       "...          ...                ...           ...    ...   ...     ...   \n",
       "2018-04-14 197.2            15900.0          32.2    0.0   0.5     0.6   \n",
       "2018-04-15 195.0            13612.9          27.6    0.0   0.5     0.6   \n",
       "2018-04-16 192.8            11325.9          23.0    0.0   0.5     0.6   \n",
       "2018-04-17 190.5             9038.9          18.4    0.0   0.5     0.6   \n",
       "2018-04-18 188.3             6751.9          13.9    0.0   0.5     0.6   \n",
       "\n",
       "           EBIDT_Q EPS_Q EQCAP_Q ETR_Q    ...     REVSH_Q SHARE_Q SR_Q TAX_Q  \\\n",
       "2012-09-30    20.2  -0.3    13.0   0.4    ...        44.0     1.3 57.6  12.4   \n",
       "2012-10-01    20.1  -0.3    13.0   0.4    ...        44.0     1.3 57.6  12.4   \n",
       "2012-10-02    20.0  -0.3    13.0   0.4    ...        43.9     1.3 57.5  12.3   \n",
       "2012-10-03    19.9  -0.3    13.0   0.4    ...        43.9     1.3 57.4  12.2   \n",
       "2012-10-04    19.8  -0.3    13.0   0.4    ...        43.8     1.3 57.4  12.1   \n",
       "...            ...   ...     ...   ...    ...         ...     ...  ...   ...   \n",
       "2018-04-14    16.5   7.3    13.0   0.3    ...        65.8     1.3 84.8   6.2   \n",
       "2018-04-15    16.5   7.3    13.0   0.3    ...        65.8     1.3 84.8   6.2   \n",
       "2018-04-16    16.5   7.3    13.0   0.3    ...        65.8     1.3 84.8   6.2   \n",
       "2018-04-17    16.5   7.3    13.0   0.3    ...        65.8     1.3 84.8   6.3   \n",
       "2018-04-18    16.5   7.3    13.0   0.3    ...        65.9     1.3 84.8   6.3   \n",
       "\n",
       "           TI_Q monthday month weekday Counter     Ticker  \n",
       "2012-09-30 59.2     30.0   9.0     7.0       1  NSE/ARIES  \n",
       "2012-10-01 59.1      1.0  10.0     1.0       2  NSE/ARIES  \n",
       "2012-10-02 59.1      2.0  10.0     2.0       3  NSE/ARIES  \n",
       "2012-10-03 59.0      3.0  10.0     3.0       4  NSE/ARIES  \n",
       "2012-10-04 58.9      4.0  10.0     4.0       5  NSE/ARIES  \n",
       "...         ...      ...   ...     ...     ...        ...  \n",
       "2018-04-14 84.6     14.0   4.0     6.0     104  NSE/ARIES  \n",
       "2018-04-15 84.6     15.0   4.0     7.0     105  NSE/ARIES  \n",
       "2018-04-16 84.6     16.0   4.0     1.0     106  NSE/ARIES  \n",
       "2018-04-17 84.6     17.0   4.0     2.0     107  NSE/ARIES  \n",
       "2018-04-18 84.6     18.0   4.0     3.0     108  NSE/ARIES  \n",
       "\n",
       "[2027 rows x 31 columns]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p5[p5.items[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Column identification \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:: ['EQCAP_Q', 'TotalTradeQuantity', 'ETR_Q', 'MCAP_Q', 'OPMSH_Q', 'PBDT_Q', 'OPSH1Q_Q', 'EPS_Q', 'NP_Q', 'DIVSH_Q', 'OI_Q', 'INT_Q', 'REVSH_Q', 'TI_Q', 'SR_Q', 'PBT_Q', 'TAX_Q', 'Turnover_Lacs', 'FV_Q', 'OP_Q', 'DEP_Q', 'EBIDT_Q', 'SHARE_Q', 'OEXPNS_Q']\n",
      "\n",
      "\n",
      "\n",
      "Target::   Return\n"
     ]
    }
   ],
   "source": [
    "counter_cols=[]\n",
    "weekday_cols=[]\n",
    "monthday_cols=[]\n",
    "month_cols=[]\n",
    "\n",
    "redunt_cols=[\"Counter\",\"weekday\", \"monthday\", \"month\", \"Close\", \"Date\", \"Ticker\"]\n",
    "\n",
    "# for col in d4.columns:\n",
    "d5n_cols_filtered=set(d5n.columns) -set(redunt_cols)\n",
    "d5n_cols_filtered=list(d5n_cols_filtered)\n",
    "\n",
    "for col in d5n_cols_filtered: \n",
    "\n",
    "    if \"Return\" in col:\n",
    "        target=col\n",
    "    \n",
    "    elif \"weekday\" in col:\n",
    "        weekday_cols.append(col)\n",
    "    elif \"monthday\" in col:\n",
    "        monthday_cols.append(col)\n",
    "    elif \"month\" in col and \"month_day\" not in col:\n",
    "        month_cols.append(col)\n",
    "    \n",
    "    elif \"Counter\" in col:\n",
    "        counter_cols.append(col)\n",
    "        \n",
    "one_hot_cols= counter_cols + weekday_cols + monthday_cols + month_cols  \n",
    "\n",
    "one_hot_issue= set(one_hot_cols)-set(list(d3n.columns ))\n",
    "\n",
    "# one_hot_cols= set(one_hot_cols)- one_hot_issue \n",
    "one_hot_cols=list(one_hot_cols)\n",
    "\n",
    "# normalize_cols= set(d5n_cols_filtered) - set(one_hot_cols)\n",
    "# normalize_cols=list(normalize_cols)\n",
    "\n",
    "feature_cols= set(d5n_cols_filtered) -set(one_hot_cols) - set([\"Return\"])\n",
    "feature_cols=list(feature_cols) \n",
    "\n",
    "\n",
    "print(\"Features:: {}\".format(feature_cols))\n",
    "print(\"\\n\\n\")\n",
    "print(\"Target::   {}\".format(target))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ** Starting NN Model from this part **\n",
    "\n",
    "### Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_features(df):\n",
    "    \n",
    "    \"\"\"\n",
    "    Parameter:\n",
    "        Dataframe \n",
    "    Return:\n",
    "        Dataframe: with features only\n",
    "    \"\"\"\n",
    "    \n",
    "    selected_features = df[feature_cols]\n",
    "    \n",
    "#     selected_features = df[one_hot_cols]\n",
    "    processed_features = selected_features.copy()\n",
    "    \n",
    "    \n",
    "    return processed_features\n",
    "\n",
    "def preprocess_targets(df):\n",
    "    \"\"\"\n",
    "    Parameter:\n",
    "        Dataframe:\n",
    "    Return:\n",
    "        Datafreme with target values only\n",
    "    \"\"\"\n",
    "    \n",
    "    output_targets=pd.DataFrame()\n",
    "    \n",
    "    output_targets[\"Return\"] = df[target]\n",
    "    \n",
    "    \n",
    "    return output_targets\n",
    "\n",
    "# Output Feature Column\n",
    "\n",
    "def construct_feature_columns(input_features):\n",
    "    return set([\n",
    "        tf.feature_column.numeric_column(my_feature)\n",
    "        for my_feature in input_features \n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Input Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_input_fn(\n",
    "    features, \n",
    "    targets, \n",
    "    batch_size=1, \n",
    "    shuffle=True, \n",
    "    num_epochs=None):\n",
    "    \n",
    "        \n",
    "    \n",
    "        \"\"\" Parameters: \n",
    "        features: pd dataframe of feature\n",
    "        targets: pd dataframe of targets\n",
    "        batch_size: size of batch\n",
    "        shuffle shuffle data or not \n",
    "        num_epochs:  number of runs \n",
    "        \n",
    "    \n",
    "        Returns:\n",
    "        Tuple of (features, lables) for next data batch\n",
    "        \"\"\"\n",
    "        \n",
    "        # Convert df into dict of np.array.\n",
    "        features = { \n",
    "                    key:np.array(value) \n",
    "                    for key, value in dict(features).items() \n",
    "                   }\n",
    "        \n",
    "        #Contruct a dataset, and configure batching/repaeating.\n",
    "        ds= Dataset.from_tensor_slices((features, targets))\n",
    "        ds= ds.batch(batch_size).repeat(num_epochs)\n",
    "        \n",
    "        # Shuffle if ordered\n",
    "        if shuffle:\n",
    "            ds =ds.shuffle(1000)\n",
    "            \n",
    "        \n",
    "        # Return next batch of the data\n",
    "        features, labels =ds.make_one_shot_iterator().get_next()\n",
    "        \n",
    "        return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn_model(\n",
    "    learning_rate, \n",
    "    steps, \n",
    "    batch_size,\n",
    "    hidden_units,\n",
    "    training_examples,\n",
    "    training_targets,\n",
    "    validation_examples,\n",
    "    validation_targets):\n",
    "\n",
    "    \n",
    "    \n",
    "    # How often you wnat updates:    \n",
    "    periods =10\n",
    "    steps_per_period = steps/periods\n",
    "    \n",
    "    \"\"\" Parameters:\n",
    "    learning_rate: how big should our step should be \n",
    "    steps: how many times should we process batch\n",
    "    batch_size: sample size \n",
    "    input_feature: what should be the input \n",
    "    \"\"\"\n",
    "    \n",
    "    #Configure regressor:\n",
    "    my_optimizer= tf.train.AdamOptimizer(learning_rate= learning_rate)\n",
    "    dnn_regressor = tf.estimator.DNNRegressor(\n",
    "        feature_columns=construct_feature_columns(training_examples),\n",
    "        hidden_units=hidden_units,\n",
    "        optimizer=my_optimizer,\n",
    "        activation_fn=tf.nn.relu\n",
    "            \n",
    "        )\n",
    "    \n",
    "    # Creating input pfunction \n",
    "    \n",
    "    training_input_fn = lambda: my_input_fn(\n",
    "        training_examples,\n",
    "        training_targets[\"Return\"],\n",
    "        batch_size=batch_size)\n",
    "    \n",
    "    predict_training_input_fn = lambda: my_input_fn(\n",
    "        training_examples,\n",
    "        training_targets[\"Return\"],\n",
    "        num_epochs=1,\n",
    "        shuffle=False)\n",
    "    \n",
    "    predict_validation_input_fn = lambda: my_input_fn(\n",
    "        validation_examples,\n",
    "        validation_targets[\"Return\"],\n",
    "        num_epochs=1,\n",
    "        shuffle=False)\n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "    # Trainign model from below code\n",
    "    print \"Training started:\"\n",
    "    print  \"RMSE on models are:\"\n",
    "    training_rmses=[]\n",
    "    validation_rmses=[]\n",
    "   \n",
    "    for  period in  range(0, periods):\n",
    "        dnn_regressor.train(\n",
    "            input_fn = training_input_fn,\n",
    "            steps = steps_per_period\n",
    "            \n",
    "        )\n",
    "        \n",
    "    \n",
    "        # Take a break and and compute some predictions \n",
    "    \n",
    "        training_predictions =dnn_regressor.predict(input_fn=predict_training_input_fn)\n",
    "        training_predictions = np.array([\n",
    "                            item[\"predictions\"][0]\n",
    "                            for item in training_predictions \n",
    "                           ])\n",
    "    \n",
    "        validation_predictions =dnn_regressor.predict(input_fn=predict_validation_input_fn)\n",
    "        validation_predictions = np.array([\n",
    "                            item[\"predictions\"][0]\n",
    "                            for item in validation_predictions \n",
    "                           ])\n",
    "    \n",
    "        \n",
    "        \n",
    "        # Compute loss\n",
    "        training_mse=metrics.mean_squared_error(training_predictions, training_targets)\n",
    "        training_rmse=math.sqrt( training_mse )\n",
    "        \n",
    "        validation_mse=metrics.mean_squared_error(validation_predictions, validation_targets)\n",
    "        validation_rmse=math.sqrt( validation_mse )\n",
    "        \n",
    "        \n",
    "        #Print current loss\n",
    "        print \"period %02d: %0.2f\" % (period, training_rmse)\n",
    "        \n",
    "        #Save rmse\n",
    "        training_rmses.append(training_rmse)\n",
    "        validation_rmses.append(validation_rmse)\n",
    "       \n",
    "    \n",
    "    print \"Model training finished.\"\n",
    "    \n",
    "    # Output graph of loss metrics over periods. \n",
    "    plt.ylabel('RMSE')\n",
    "    plt.xlabel(\"Periods\")\n",
    "    plt.title(\"RMSE vs Periods\")\n",
    "    plt.tight_layout()\n",
    "    plt.plot(training_rmses, label=\"training\")\n",
    "    plt.plot(validation_rmses, label=\"validation\")\n",
    "    plt.legend()\n",
    "  \n",
    "\n",
    "    return  dnn_regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Floating error avoadance:\n",
    "\n",
    "length_of_df=int(len(d3n))\n",
    "r=.9\n",
    "\n",
    "\n",
    "# Using rargets  tio factor r\n",
    "training_count   = int(r*length_of_df)  \n",
    "validation_count = length_of_df-training_count\n",
    "\n",
    "#Shuffle all the valaues \n",
    "d3n=d3n.reindex(np.random.permutation(d3n.index))\n",
    "\n",
    "training_examples   = preprocess_features(d3n.head(training_count))\n",
    "training_targets    = preprocess_targets( d3n.head(training_count))\n",
    "\n",
    "validation_examples = preprocess_features(d3n.tail(validation_count))\n",
    "validation_targets  = preprocess_targets( d3n.tail(validation_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started:\n",
      "RMSE on models are:\n",
      "period 00: 0.25\n"
     ]
    }
   ],
   "source": [
    "dnn_regressor= train_nn_model(learning_rate=0.0000001, steps=1000000, batch_size=5000, hidden_units=[24,20,20],\n",
    "    training_examples=training_examples,\n",
    "    training_targets=training_targets,\n",
    "    validation_examples=validation_examples,\n",
    "    validation_targets=validation_targets\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predcicting stock returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_examples = preprocess_features(d4n)\n",
    "stock_targets  = preprocess_targets(d4n)\n",
    "\n",
    "predict_stock_input_fn = lambda: my_input_fn(\n",
    "        stock_examples,\n",
    "        stock_targets[\"Return\"],\n",
    "        num_epochs=1,\n",
    "        shuffle=False)\n",
    "\n",
    "stock_predictions =dnn_regressor.predict(input_fn=predict_stock_input_fn)\n",
    "stock_predictions = np.array([\n",
    "                        item[\"predictions\"][0]\n",
    "                        for item in stock_predictions \n",
    "                       ])\n",
    "\n",
    "print list(stock_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Saving prediction to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d6_cols=d4[\"Ticker\"].unique()\n",
    "d6_index=d4[\"Date\"].unique()\n",
    "\n",
    "d6=pd.DataFrame(columns=d6_cols, index=d6_index)\n",
    "\n",
    "j=0\n",
    "for tick in d6.columns: \n",
    "    d6[tick]=stock_predictions[j:j+7]\n",
    "    j+=7\n",
    "d6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Denormalizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoramlize(df, base_df, col):\n",
    "    \n",
    "    min_v=min(base_df[col]) \n",
    "    max_v=max(base_df[col])\n",
    "    delta = max_v-min_v\n",
    "\n",
    "    print(\"Min:  {}\".format(min_v))\n",
    "    print(\"Max:  {}\".format(max_v))\n",
    "    print(\"delta:{}\".format(delta))\n",
    "\n",
    "\n",
    "    for col in df.columns:\n",
    "        df[col]=df[[col]].apply(lambda x: min_v + (x*(delta/1)) )\n",
    "        \n",
    "def denoramlize_2(df, base_df, col):\n",
    "    \n",
    "    mean_v=base_df[col].mean() \n",
    "    std_dv=max(base_df[col])\n",
    "    \n",
    "    print(\"Mean  :  {}\".format(mean_v))\n",
    "    print(\"Std_dv:  {}\".format(std_dv))\n",
    "    \n",
    "\n",
    "\n",
    "    for col in df.columns:\n",
    "        df[col]=df[[col]].apply(lambda x: mean_v + ((x*std_dv)/1) )        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoramlize(d6, d5, \"Return\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "\n",
    "### Saving Data..... \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sector_name=w.kwargs[\"sector_name\"]\n",
    "\n",
    "result_file_name= \"../Panel/Result/Predicted/\"+sector_name+\".csv\"\n",
    "\n",
    "d6.to_csv(result_file_name) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
