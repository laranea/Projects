{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span><ul class=\"toc-item\"><li><span><a href=\"#Background\" data-toc-modified-id=\"Background-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Background</a></span></li><li><span><a href=\"#Problem\" data-toc-modified-id=\"Problem-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Problem</a></span></li><li><span><a href=\"#Target-Audience\" data-toc-modified-id=\"Target-Audience-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Target Audience</a></span></li></ul></li><li><span><a href=\"#Data\" data-toc-modified-id=\"Data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#What-data-do-we-need?\" data-toc-modified-id=\"What-data-do-we-need?-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>What data do we need?</a></span><ul class=\"toc-item\"><li><span><a href=\"#Scraping-neighbourhood-and-boroughs-details-from-Wiki-&amp;-other-websites\" data-toc-modified-id=\"Scraping-neighbourhood-and-boroughs-details-from-Wiki-&amp;-other-websites-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Scraping neighbourhood and boroughs details from Wiki &amp; other websites</a></span></li><li><span><a href=\"#Getting-Location-Data-Open-Street-Map-API-Nominatim\" data-toc-modified-id=\"Getting-Location-Data-Open-Street-Map-API-Nominatim-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Getting Location Data Open Street Map API Nominatim</a></span></li><li><span><a href=\"#Getting-Foursqure-Data\" data-toc-modified-id=\"Getting-Foursqure-Data-2.1.3\"><span class=\"toc-item-num\">2.1.3&nbsp;&nbsp;</span>Getting Foursqure Data</a></span></li></ul></li><li><span><a href=\"#Preprocessing-Data-for-modelling\" data-toc-modified-id=\"Preprocessing-Data-for-modelling-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Preprocessing Data for modelling</a></span><ul class=\"toc-item\"><li><span><a href=\"#Removing-rows-with-empty-cells\" data-toc-modified-id=\"Removing-rows-with-empty-cells-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Removing rows with empty cells</a></span></li><li><span><a href=\"#Reducing-number-of-categories-or-features-set.\" data-toc-modified-id=\"Reducing-number-of-categories-or-features-set.-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>Reducing number of categories or features set.</a></span></li><li><span><a href=\"#Converting-Category-column-to-one-hot-encoding\" data-toc-modified-id=\"Converting-Category-column-to-one-hot-encoding-2.2.3\"><span class=\"toc-item-num\">2.2.3&nbsp;&nbsp;</span>Converting Category column to one hot encoding</a></span></li></ul></li><li><span><a href=\"#Describing-Data\" data-toc-modified-id=\"Describing-Data-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Describing Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Describing-data's-X\" data-toc-modified-id=\"Describing-data's-X-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>Describing data's X</a></span></li><li><span><a href=\"#Describing-data's-y\" data-toc-modified-id=\"Describing-data's-y-2.3.2\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>Describing data's y</a></span></li></ul></li></ul></li><li><span><a href=\"#Methodology\" data-toc-modified-id=\"Methodology-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Methodology</a></span><ul class=\"toc-item\"><li><span><a href=\"#Exploratory-Data-Analysis\" data-toc-modified-id=\"Exploratory-Data-Analysis-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Exploratory Data Analysis</a></span><ul class=\"toc-item\"><li><span><a href=\"#Finding-correlation-between-feature-sets\" data-toc-modified-id=\"Finding-correlation-between-feature-sets-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>Finding correlation between feature sets</a></span></li><li><span><a href=\"#Finding-box-plot-of-data's-X\" data-toc-modified-id=\"Finding-box-plot-of-data's-X-3.1.2\"><span class=\"toc-item-num\">3.1.2&nbsp;&nbsp;</span>Finding box plot of data's X</a></span></li><li><span><a href=\"#City-wise-no-of-venues\" data-toc-modified-id=\"City-wise-no-of-venues-3.1.3\"><span class=\"toc-item-num\">3.1.3&nbsp;&nbsp;</span>City wise no of venues</a></span></li><li><span><a href=\"#City-wise-venues-composition.\" data-toc-modified-id=\"City-wise-venues-composition.-3.1.4\"><span class=\"toc-item-num\">3.1.4&nbsp;&nbsp;</span>City wise venues composition.</a></span></li></ul></li><li><span><a href=\"#Choosing-Technique\" data-toc-modified-id=\"Choosing-Technique-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Choosing Technique</a></span></li><li><span><a href=\"#Applying-Technique\" data-toc-modified-id=\"Applying-Technique-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Applying Technique</a></span><ul class=\"toc-item\"><li><span><a href=\"#Normalization\" data-toc-modified-id=\"Normalization-3.3.1\"><span class=\"toc-item-num\">3.3.1&nbsp;&nbsp;</span>Normalization</a></span></li><li><span><a href=\"#Multiplication\" data-toc-modified-id=\"Multiplication-3.3.2\"><span class=\"toc-item-num\">3.3.2&nbsp;&nbsp;</span>Multiplication</a></span></li><li><span><a href=\"#Finding-top-10-neighbhorhood\" data-toc-modified-id=\"Finding-top-10-neighbhorhood-3.3.3\"><span class=\"toc-item-num\">3.3.3&nbsp;&nbsp;</span>Finding top 10 neighbhorhood</a></span></li><li><span><a href=\"#Finding-top-10-Venue-by-numbers-in-neighbhorhood\" data-toc-modified-id=\"Finding-top-10-Venue-by-numbers-in-neighbhorhood-3.3.4\"><span class=\"toc-item-num\">3.3.4&nbsp;&nbsp;</span>Finding top 10 Venue by numbers in neighbhorhood</a></span></li></ul></li></ul></li><li><span><a href=\"#Result\" data-toc-modified-id=\"Result-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Result</a></span><ul class=\"toc-item\"><li><span><a href=\"#Normal-Plot-of-score\" data-toc-modified-id=\"Normal-Plot-of-score-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Normal Plot of score</a></span><ul class=\"toc-item\"><li><span><a href=\"#Mean\" data-toc-modified-id=\"Mean-4.1.1\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span>Mean</a></span></li><li><span><a href=\"#Standard-Deviation\" data-toc-modified-id=\"Standard-Deviation-4.1.2\"><span class=\"toc-item-num\">4.1.2&nbsp;&nbsp;</span>Standard Deviation</a></span></li></ul></li><li><span><a href=\"#Tableau-Presentation\" data-toc-modified-id=\"Tableau-Presentation-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Tableau Presentation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Making-dataframe-for-arrows-file.\" data-toc-modified-id=\"Making-dataframe-for-arrows-file.-4.2.1\"><span class=\"toc-item-num\">4.2.1&nbsp;&nbsp;</span>Making dataframe for arrows file.</a></span></li><li><span><a href=\"#Making-data-frame-for-top-10-venues\" data-toc-modified-id=\"Making-data-frame-for-top-10-venues-4.2.2\"><span class=\"toc-item-num\">4.2.2&nbsp;&nbsp;</span>Making data frame for top 10 venues</a></span></li><li><span><a href=\"#Tableau-Dashboard-Link:--https://sagarrathi.github.io\" data-toc-modified-id=\"Tableau-Dashboard-Link:--https://sagarrathi.github.io-4.2.3\"><span class=\"toc-item-num\">4.2.3&nbsp;&nbsp;</span>Tableau Dashboard Link:  <a href=\"https://sagarrathi.github.io\" target=\"_blank\">https://sagarrathi.github.io</a></a></span></li></ul></li></ul></li><li><span><a href=\"#Discussion-&amp;-Recomendation\" data-toc-modified-id=\"Discussion-&amp;-Recomendation-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Discussion &amp; Recomendation</a></span></li><li><span><a href=\"#Conculsion\" data-toc-modified-id=\"Conculsion-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Conculsion</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Finding Similar Neighbourhood to Migrate.</h1>\n",
    "<p><strong>A Simple inter-city Recommender System</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "### Background\n",
    "We all love Spotify or many of us do. Spotify has offices in New York (USA) and Toronto (Canada).\n",
    "Suppose the company decides to shuffle some of its employees between two cities, and James(employee) of NYC and Thomas(employee) of Toronto are being told exchange themselves between offices in lieu of pay rise.\n",
    "Both James and Thomas agree to exchange for the benefit of a pay rise.\n",
    "### Problem\n",
    "The problem is that both are very stubborn people. They think that they will be able to find the most similar environment in both of these cities. \n",
    "After doing hard research they fail and they give up the task of exchanging places. So the HR of the company ask us to solve this problem or to better find suitable (similar) alternate neighbourhood between these two cities.\n",
    "We ask the HR what does he/she mean by similar neighbourhood.\n",
    "The HR told us that they need similar cities on the basis of leaving condition and amenities present in the surrounding area.\n",
    "So, our task here is to find similar intercity neighbourhood and give to HR so that the next time they do some shuffling atleast they will have data and can recommend a suitable neighbourhood to the employee. \n",
    "\n",
    "### Target Audience \n",
    "Our target audience is various HR who want to send their employees  to different cities and also various people who want to shift cities and do not know where to go being very stubborn of choices. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "### What data do we need?\n",
    "Our problem statement has made a very vague suggestion on similar cities. What data we need in this project can be listed by asking right questions………... and answering them too.\n",
    "<style type=\"text/css\">\n",
    "\ttable.tableizer-table {\n",
    "\t\tfont-size: 12px;\n",
    "\t\tborder: 1px solid #CCC; \n",
    "\t\tfont-family: Arial, Helvetica, sans-serif;\n",
    "\t} \n",
    "\t.tableizer-table td {\n",
    "\t\tpadding: 4px;\n",
    "\t\tmargin: 3px;\n",
    "\t\tborder: 1px solid #CCC;\n",
    "\t}\n",
    "\t.tableizer-table th {\n",
    "\t\tbackground-color: #104E8B; \n",
    "\t\tcolor: #FFF;\n",
    "\t\tfont-weight: bold;\n",
    "\t}\n",
    "</style>\n",
    "<table class=\"tableizer-table\">\n",
    "<thead><tr class=\"tableizer-firstrow\"><th>No.</th><th>Questions</th><th>Answers</th></tr></thead><tbody>\n",
    " <tr><td>1</td><td>Do you know name of the neighbourhood and boroughs of cities?</td><td>We do not know yet but Wikipedia knows it all, so we will scrape that data. </td></tr>\n",
    " <tr><td>2</td><td>Before obtaining any data on amenities around do you know the exact GPS coordinates of those places?</td><td>We don't remember GPS coordinate of ouwn home but in this case, Open Street Map and Google Map know all about this data, so we will use their API (geopy) to solve this problem. </td></tr>\n",
    " <tr><td>3</td><td>Ok great that you know GPS coordinate but do know what paces are nearby that location like garden, parks, hotels and etc. </td><td>To be honest, I am a couch potato, I don't know the name of the restaurant nearby my neighbour but I often use the Foursquare app to explore any place, I heard that they have API too and we can get a large amount of data from those API. So we will use the foursquare API.</td></tr>\n",
    "</tbody></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scraping neighbourhood and boroughs details from Wiki & other websites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up main libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up Beautiful Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib3\n",
    "\n",
    "\n",
    "nyc_url=\"https://www.baruch.cuny.edu/nycdata/population-geography/neighborhoods.htm\"\n",
    "tor_url=\"https://en.wikipedia.org/wiki/Demographics_of_Toronto_neighbourhoods\"\n",
    "\n",
    "\n",
    "http=urllib3.PoolManager()\n",
    "\n",
    "nyc_doc=http.request('GET', nyc_url).data\n",
    "tor_doc=http.request('GET', tor_url).data\n",
    "\n",
    "nyc_soup=BeautifulSoup(nyc_doc, \"html.parser\")\n",
    "tor_soup=BeautifulSoup(tor_doc, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Brooklyn', 'Bronx', 'Manhattan', 'Queens', 'Staten Island']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boroughs=nyc_soup.findAll(\"table\")[1].findAll(\"tr\")[4:5][0].findAll(\"td\")\n",
    "# boroughs.findAll(\"td\")\n",
    "nyc_boroughs=[]\n",
    "for b in boroughs:\n",
    "    b=b.text.strip()\n",
    "    if b!=\"\":\n",
    "        nyc_boroughs.append(b)\n",
    "nyc_boroughs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_neighbhourhoods=nyc_soup.findAll(\"table\")[1].findAll(\"tr\")[5:-12]\n",
    "# nyc_neighbhourhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total NYC Data: 329\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Neighborhoods</th>\n",
       "      <th>Boroughs</th>\n",
       "      <th>City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bath Beach</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>NYC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allerton</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>NYC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Battery Park City</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>NYC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arverne</td>\n",
       "      <td>Queens</td>\n",
       "      <td>NYC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Annadale</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>NYC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Neighborhoods       Boroughs City\n",
       "0         Bath Beach       Brooklyn  NYC\n",
       "1           Allerton          Bronx  NYC\n",
       "2  Battery Park City      Manhattan  NYC\n",
       "3            Arverne         Queens  NYC\n",
       "4           Annadale  Staten Island  NYC"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyc_neighbhourhoods_list=[]\n",
    "nyc_boroughs_list=[]\n",
    "nyc_city_list=[]\n",
    "\n",
    "for n in nyc_neighbhourhoods:\n",
    "#     print(n)\n",
    "    for i in range(1,6):\n",
    "        try:\n",
    "            neighbhourhood=n.findAll(\"td\")[i].text.strip()\n",
    "            if neighbhourhood!=\"\":\n",
    "                borough=nyc_boroughs[i-1]\n",
    "                nyc_neighbhourhoods_list.append(neighbhourhood)\n",
    "                nyc_boroughs_list.append(borough)\n",
    "                nyc_city_list.append(\"NYC\")\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "nyc_dict={\"Neighborhoods\":nyc_neighbhourhoods_list,\n",
    "         \"Boroughs\":nyc_boroughs_list,\n",
    "        \"City\":nyc_city_list}\n",
    "\n",
    "\n",
    "nyc_df=pd.DataFrame(nyc_dict)\n",
    "print(\"Total NYC Data:\",len(nyc_df))\n",
    "nyc_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------NYC Data Retrival Done---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tor_neighbhourhoods=tor_soup.findAll(\"table\")[1].findAll(\"tr\")\n",
    "# print(tor_neighbhourhoods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total TOR Data: 174\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Neighborhoods</th>\n",
       "      <th>Boroughs</th>\n",
       "      <th>City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agincourt</td>\n",
       "      <td>Scarborough</td>\n",
       "      <td>TOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alderwood</td>\n",
       "      <td>Etobicoke</td>\n",
       "      <td>TOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alexandra Park</td>\n",
       "      <td>Old City of Toronto</td>\n",
       "      <td>TOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Allenby</td>\n",
       "      <td>Old City of Toronto</td>\n",
       "      <td>TOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amesbury</td>\n",
       "      <td>North York</td>\n",
       "      <td>TOR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Neighborhoods             Boroughs City\n",
       "0       Agincourt          Scarborough  TOR\n",
       "1       Alderwood            Etobicoke  TOR\n",
       "2  Alexandra Park  Old City of Toronto  TOR\n",
       "3         Allenby  Old City of Toronto  TOR\n",
       "4        Amesbury           North York  TOR"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tor_boroughs_abv={\n",
    "            \"OCoT\":\"Old City of Toronto\",\n",
    "            \"S\":\"Scarborough\",\n",
    "            \"NY\":\"North York\",\n",
    "            \"E\":\"Etobicoke\", \n",
    "            \"Y\":\"York\", \n",
    "            \"EY\":\"East York\", \n",
    "            }\n",
    "\n",
    "tor_boroughs_list=[]\n",
    "tor_neighbhourhoods_list=[]\n",
    "tor_city_list=[]\n",
    "\n",
    "for n in tor_neighbhourhoods[2:]:\n",
    "    row=n.findAll(\"td\")\n",
    "    \n",
    "    neighbhourhood=row[0].text.strip()\n",
    "    borough=tor_boroughs_abv[row[1].text.strip()]\n",
    "    \n",
    "    tor_neighbhourhoods_list.append(neighbhourhood)\n",
    "    tor_boroughs_list.append(borough)\n",
    "    tor_city_list.append(\"TOR\")\n",
    "\n",
    "\n",
    "\n",
    "tor_dict={\"Neighborhoods\":tor_neighbhourhoods_list,\n",
    "         \"Boroughs\":tor_boroughs_list,\n",
    "        \"City\":tor_city_list}\n",
    "\n",
    "tor_df=pd.DataFrame(tor_dict)\n",
    "print(\"Total TOR Data:\",len(tor_df))\n",
    "tor_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After merging NYC and TOR we have: 503 of records\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Neighborhoods</th>\n",
       "      <th>Boroughs</th>\n",
       "      <th>City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bath Beach</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>NYC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allerton</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>NYC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Battery Park City</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>NYC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arverne</td>\n",
       "      <td>Queens</td>\n",
       "      <td>NYC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Annadale</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>NYC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>Woburn</td>\n",
       "      <td>Scarborough</td>\n",
       "      <td>TOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>Wychwood</td>\n",
       "      <td>Old City of Toronto</td>\n",
       "      <td>TOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>York Mills</td>\n",
       "      <td>North York</td>\n",
       "      <td>TOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>York University Heights</td>\n",
       "      <td>North York</td>\n",
       "      <td>TOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>Yorkville</td>\n",
       "      <td>Old City of Toronto</td>\n",
       "      <td>TOR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>503 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Neighborhoods             Boroughs City\n",
       "0                 Bath Beach             Brooklyn  NYC\n",
       "1                   Allerton                Bronx  NYC\n",
       "2          Battery Park City            Manhattan  NYC\n",
       "3                    Arverne               Queens  NYC\n",
       "4                   Annadale        Staten Island  NYC\n",
       "..                       ...                  ...  ...\n",
       "169                   Woburn          Scarborough  TOR\n",
       "170                 Wychwood  Old City of Toronto  TOR\n",
       "171               York Mills           North York  TOR\n",
       "172  York University Heights           North York  TOR\n",
       "173                Yorkville  Old City of Toronto  TOR\n",
       "\n",
       "[503 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=nyc_df.append(tor_df)\n",
    "print(\"After merging NYC and TOR we have:\",len(df), \"of records\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"nyc_tor_list.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------Checkpoint-----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"nyc_tor_list.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting Location Data Open Street Map API Nominatim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up geopy library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "df[\"Latitude\"]=np.NaN\n",
    "df[\"Longitude\"]=np.NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making location extractor Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finding_location(df,start_index, end_index):\n",
    "    \n",
    "    user_agent=\"projhlhlooh7878\"\n",
    "    geolocator=Nominatim(user_agent=user_agent, timeout=15)\n",
    "\n",
    "    for i in range(start_index, end_index):\n",
    "#         print(\"Index:\",i)\n",
    "        neighbhourhood=df.iloc[i][\"Neighborhoods\"]\n",
    "        borough=df.iloc[i][\"Boroughs\"]\n",
    "        city_code=df.iloc[i][\"City\"]\n",
    "\n",
    "        if city_code==\"NYC\":\n",
    "            city=\"New York\"\n",
    "        else:\n",
    "            city=\"Toronto\"\n",
    "\n",
    "        neighbhourhood=neighbhourhood.split(\",\")[0]\n",
    "\n",
    "        address=neighbhourhood+\", \"+city\n",
    "#         print(\"Address:\", address)\n",
    "\n",
    "        location=geolocator.geocode(address)\n",
    "\n",
    "        try:\n",
    "            lat=location.latitude\n",
    "            long=location.longitude\n",
    "        except:\n",
    "            lat=np.NaN\n",
    "            long=np.NaN\n",
    "\n",
    "        df.at[i,\"Latitude\"]=lat\n",
    "        df.at[i,\"Longitude\"]=long"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating multiple threads to make data retrieval faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-44:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/urllib/request.py\", line 1317, in do_open\n",
      "    encode_chunked=req.has_header('Transfer-encoding'))\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/http/client.py\", line 1229, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/http/client.py\", line 1275, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/http/client.py\", line 1224, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/http/client.py\", line 1016, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/http/client.py\", line 956, in send\n",
      "    self.connect()\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/http/client.py\", line 1384, in connect\n",
      "    super().connect()\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/http/client.py\", line 928, in connect\n",
      "    (self.host,self.port), self.timeout, self.source_address)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/socket.py\", line 727, in create_connection\n",
      "    raise err\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/socket.py\", line 716, in create_connection\n",
      "    sock.connect(sa)\n",
      "OSError: [Errno 101] Network is unreachable\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/site-packages/geopy/geocoders/base.py\", line 355, in _call_geocoder\n",
      "    page = requester(req, timeout=timeout, **kwargs)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/urllib/request.py\", line 525, in open\n",
      "    response = self._open(req, data)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/urllib/request.py\", line 543, in _open\n",
      "    '_open', req)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/urllib/request.py\", line 503, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/urllib/request.py\", line 1360, in https_open\n",
      "    context=self._context, check_hostname=self._check_hostname)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/urllib/request.py\", line 1319, in do_open\n",
      "    raise URLError(err)\n",
      "urllib.error.URLError: <urlopen error [Errno 101] Network is unreachable>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/threading.py\", line 917, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/threading.py\", line 865, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-23-061a4cf914d4>\", line 22, in finding_location\n",
      "    location=geolocator.geocode(address)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/site-packages/geopy/geocoders/osm.py\", line 387, in geocode\n",
      "    self._call_geocoder(url, timeout=timeout), exactly_one\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/site-packages/geopy/geocoders/base.py\", line 380, in _call_geocoder\n",
      "    raise GeocoderUnavailable('Service not available')\n",
      "geopy.exc.GeocoderUnavailable: Service not available\n",
      "\n",
      "Exception in thread Thread-43:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/urllib/request.py\", line 1317, in do_open\n",
      "    encode_chunked=req.has_header('Transfer-encoding'))\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/http/client.py\", line 1229, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/http/client.py\", line 1275, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/http/client.py\", line 1224, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/http/client.py\", line 1016, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/http/client.py\", line 956, in send\n",
      "    self.connect()\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/http/client.py\", line 1384, in connect\n",
      "    super().connect()\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/http/client.py\", line 928, in connect\n",
      "    (self.host,self.port), self.timeout, self.source_address)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/socket.py\", line 727, in create_connection\n",
      "    raise err\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/socket.py\", line 716, in create_connection\n",
      "    sock.connect(sa)\n",
      "OSError: [Errno 101] Network is unreachable\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/site-packages/geopy/geocoders/base.py\", line 355, in _call_geocoder\n",
      "    page = requester(req, timeout=timeout, **kwargs)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/urllib/request.py\", line 525, in open\n",
      "    response = self._open(req, data)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/urllib/request.py\", line 543, in _open\n",
      "    '_open', req)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/urllib/request.py\", line 503, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/urllib/request.py\", line 1360, in https_open\n",
      "    context=self._context, check_hostname=self._check_hostname)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/urllib/request.py\", line 1319, in do_open\n",
      "    raise URLError(err)\n",
      "urllib.error.URLError: <urlopen error [Errno 101] Network is unreachable>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/threading.py\", line 917, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/threading.py\", line 865, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-23-061a4cf914d4>\", line 22, in finding_location\n",
      "    location=geolocator.geocode(address)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/site-packages/geopy/geocoders/osm.py\", line 387, in geocode\n",
      "    self._call_geocoder(url, timeout=timeout), exactly_one\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/site-packages/geopy/geocoders/base.py\", line 380, in _call_geocoder\n",
      "    raise GeocoderUnavailable('Service not available')\n",
      "geopy.exc.GeocoderUnavailable: Service not available\n",
      "\n",
      "Exception in thread Thread-47:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/urllib/request.py\", line 1317, in do_open\n",
      "    encode_chunked=req.has_header('Transfer-encoding'))\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/http/client.py\", line 1229, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/http/client.py\", line 1275, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/http/client.py\", line 1224, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/http/client.py\", line 1016, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/http/client.py\", line 956, in send\n",
      "    self.connect()\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/http/client.py\", line 1384, in connect\n",
      "    super().connect()\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/http/client.py\", line 928, in connect\n",
      "    (self.host,self.port), self.timeout, self.source_address)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/socket.py\", line 727, in create_connection\n",
      "    raise err\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/socket.py\", line 716, in create_connection\n",
      "    sock.connect(sa)\n",
      "OSError: [Errno 101] Network is unreachable\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/site-packages/geopy/geocoders/base.py\", line 355, in _call_geocoder\n",
      "    page = requester(req, timeout=timeout, **kwargs)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/urllib/request.py\", line 525, in open\n",
      "    response = self._open(req, data)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/urllib/request.py\", line 543, in _open\n",
      "    '_open', req)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/urllib/request.py\", line 503, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/urllib/request.py\", line 1360, in https_open\n",
      "    context=self._context, check_hostname=self._check_hostname)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/urllib/request.py\", line 1319, in do_open\n",
      "    raise URLError(err)\n",
      "urllib.error.URLError: <urlopen error [Errno 101] Network is unreachable>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/threading.py\", line 917, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/threading.py\", line 865, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-23-061a4cf914d4>\", line 22, in finding_location\n",
      "    location=geolocator.geocode(address)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/site-packages/geopy/geocoders/osm.py\", line 387, in geocode\n",
      "    self._call_geocoder(url, timeout=timeout), exactly_one\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/site-packages/geopy/geocoders/base.py\", line 380, in _call_geocoder\n",
      "    raise GeocoderUnavailable('Service not available')\n",
      "geopy.exc.GeocoderUnavailable: Service not available\n",
      "\n",
      "Exception in thread Thread-41:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/urllib/request.py\", line 1317, in do_open\n",
      "    encode_chunked=req.has_header('Transfer-encoding'))\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/http/client.py\", line 1229, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/http/client.py\", line 1275, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/http/client.py\", line 1224, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/http/client.py\", line 1016, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/http/client.py\", line 956, in send\n",
      "    self.connect()\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/http/client.py\", line 1384, in connect\n",
      "    super().connect()\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/http/client.py\", line 928, in connect\n",
      "    (self.host,self.port), self.timeout, self.source_address)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/socket.py\", line 727, in create_connection\n",
      "    raise err\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/socket.py\", line 716, in create_connection\n",
      "    sock.connect(sa)\n",
      "OSError: [Errno 101] Network is unreachable\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/site-packages/geopy/geocoders/base.py\", line 355, in _call_geocoder\n",
      "    page = requester(req, timeout=timeout, **kwargs)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/urllib/request.py\", line 525, in open\n",
      "    response = self._open(req, data)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/urllib/request.py\", line 543, in _open\n",
      "    '_open', req)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/urllib/request.py\", line 503, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/urllib/request.py\", line 1360, in https_open\n",
      "    context=self._context, check_hostname=self._check_hostname)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/urllib/request.py\", line 1319, in do_open\n",
      "    raise URLError(err)\n",
      "urllib.error.URLError: <urlopen error [Errno 101] Network is unreachable>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/threading.py\", line 917, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/threading.py\", line 865, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-23-061a4cf914d4>\", line 22, in finding_location\n",
      "    location=geolocator.geocode(address)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/site-packages/geopy/geocoders/osm.py\", line 387, in geocode\n",
      "    self._call_geocoder(url, timeout=timeout), exactly_one\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/site-packages/geopy/geocoders/base.py\", line 380, in _call_geocoder\n",
      "    raise GeocoderUnavailable('Service not available')\n",
      "geopy.exc.GeocoderUnavailable: Service not available\n",
      "\n",
      "Exception in thread Thread-46:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/urllib/request.py\", line 1317, in do_open\n",
      "    encode_chunked=req.has_header('Transfer-encoding'))\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/http/client.py\", line 1229, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/http/client.py\", line 1275, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/http/client.py\", line 1224, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/http/client.py\", line 1016, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/http/client.py\", line 956, in send\n",
      "    self.connect()\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/http/client.py\", line 1384, in connect\n",
      "    super().connect()\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/http/client.py\", line 928, in connect\n",
      "    (self.host,self.port), self.timeout, self.source_address)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/socket.py\", line 727, in create_connection\n",
      "    raise err\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/socket.py\", line 716, in create_connection\n",
      "    sock.connect(sa)\n",
      "OSError: [Errno 101] Network is unreachable\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/site-packages/geopy/geocoders/base.py\", line 355, in _call_geocoder\n",
      "    page = requester(req, timeout=timeout, **kwargs)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/urllib/request.py\", line 525, in open\n",
      "    response = self._open(req, data)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/urllib/request.py\", line 543, in _open\n",
      "    '_open', req)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/urllib/request.py\", line 503, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/urllib/request.py\", line 1360, in https_open\n",
      "    context=self._context, check_hostname=self._check_hostname)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/urllib/request.py\", line 1319, in do_open\n",
      "    raise URLError(err)\n",
      "urllib.error.URLError: <urlopen error [Errno 101] Network is unreachable>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/threading.py\", line 917, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/threading.py\", line 865, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-23-061a4cf914d4>\", line 22, in finding_location\n",
      "    location=geolocator.geocode(address)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/site-packages/geopy/geocoders/osm.py\", line 387, in geocode\n",
      "    self._call_geocoder(url, timeout=timeout), exactly_one\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/site-packages/geopy/geocoders/base.py\", line 380, in _call_geocoder\n",
      "    raise GeocoderUnavailable('Service not available')\n",
      "geopy.exc.GeocoderUnavailable: Service not available\n",
      "\n",
      "Exception in thread Thread-50:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/urllib/request.py\", line 1317, in do_open\n",
      "    encode_chunked=req.has_header('Transfer-encoding'))\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/http/client.py\", line 1229, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/http/client.py\", line 1275, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/http/client.py\", line 1224, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/http/client.py\", line 1016, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/http/client.py\", line 956, in send\n",
      "    self.connect()\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/http/client.py\", line 1384, in connect\n",
      "    super().connect()\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/http/client.py\", line 928, in connect\n",
      "    (self.host,self.port), self.timeout, self.source_address)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/socket.py\", line 727, in create_connection\n",
      "    raise err\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/socket.py\", line 716, in create_connection\n",
      "    sock.connect(sa)\n",
      "OSError: [Errno 101] Network is unreachable\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/site-packages/geopy/geocoders/base.py\", line 355, in _call_geocoder\n",
      "    page = requester(req, timeout=timeout, **kwargs)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/urllib/request.py\", line 525, in open\n",
      "    response = self._open(req, data)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/urllib/request.py\", line 543, in _open\n",
      "    '_open', req)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/urllib/request.py\", line 503, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/urllib/request.py\", line 1360, in https_open\n",
      "    context=self._context, check_hostname=self._check_hostname)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/urllib/request.py\", line 1319, in do_open\n",
      "    raise URLError(err)\n",
      "urllib.error.URLError: <urlopen error [Errno 101] Network is unreachable>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/threading.py\", line 917, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/threading.py\", line 865, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-23-061a4cf914d4>\", line 22, in finding_location\n",
      "    location=geolocator.geocode(address)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/site-packages/geopy/geocoders/osm.py\", line 387, in geocode\n",
      "    self._call_geocoder(url, timeout=timeout), exactly_one\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/site-packages/geopy/geocoders/base.py\", line 380, in _call_geocoder\n",
      "    raise GeocoderUnavailable('Service not available')\n",
      "geopy.exc.GeocoderUnavailable: Service not available\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-40:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/urllib/request.py\", line 1317, in do_open\n",
      "    encode_chunked=req.has_header('Transfer-encoding'))\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/http/client.py\", line 1229, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/http/client.py\", line 1275, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/http/client.py\", line 1224, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/http/client.py\", line 1016, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/http/client.py\", line 956, in send\n",
      "    self.connect()\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/http/client.py\", line 1384, in connect\n",
      "    super().connect()\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/http/client.py\", line 928, in connect\n",
      "    (self.host,self.port), self.timeout, self.source_address)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/socket.py\", line 727, in create_connection\n",
      "    raise err\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/socket.py\", line 716, in create_connection\n",
      "    sock.connect(sa)\n",
      "OSError: [Errno 101] Network is unreachable\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/site-packages/geopy/geocoders/base.py\", line 355, in _call_geocoder\n",
      "    page = requester(req, timeout=timeout, **kwargs)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/urllib/request.py\", line 525, in open\n",
      "    response = self._open(req, data)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/urllib/request.py\", line 543, in _open\n",
      "    '_open', req)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/urllib/request.py\", line 503, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/urllib/request.py\", line 1360, in https_open\n",
      "    context=self._context, check_hostname=self._check_hostname)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/urllib/request.py\", line 1319, in do_open\n",
      "    raise URLError(err)\n",
      "urllib.error.URLError: <urlopen error [Errno 101] Network is unreachable>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/threading.py\", line 917, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/threading.py\", line 865, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-23-061a4cf914d4>\", line 22, in finding_location\n",
      "    location=geolocator.geocode(address)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/site-packages/geopy/geocoders/osm.py\", line 387, in geocode\n",
      "    self._call_geocoder(url, timeout=timeout), exactly_one\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/site-packages/geopy/geocoders/base.py\", line 380, in _call_geocoder\n",
      "    raise GeocoderUnavailable('Service not available')\n",
      "geopy.exc.GeocoderUnavailable: Service not available\n",
      "\n",
      "Exception in thread Thread-49:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/urllib/request.py\", line 1317, in do_open\n",
      "    encode_chunked=req.has_header('Transfer-encoding'))\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/http/client.py\", line 1229, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/http/client.py\", line 1275, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/http/client.py\", line 1224, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/http/client.py\", line 1016, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/http/client.py\", line 956, in send\n",
      "    self.connect()\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/http/client.py\", line 1384, in connect\n",
      "    super().connect()\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/http/client.py\", line 928, in connect\n",
      "    (self.host,self.port), self.timeout, self.source_address)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/socket.py\", line 727, in create_connection\n",
      "    raise err\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/socket.py\", line 716, in create_connection\n",
      "    sock.connect(sa)\n",
      "OSError: [Errno 101] Network is unreachable\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/site-packages/geopy/geocoders/base.py\", line 355, in _call_geocoder\n",
      "    page = requester(req, timeout=timeout, **kwargs)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/urllib/request.py\", line 525, in open\n",
      "    response = self._open(req, data)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/urllib/request.py\", line 543, in _open\n",
      "    '_open', req)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/urllib/request.py\", line 503, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/urllib/request.py\", line 1360, in https_open\n",
      "    context=self._context, check_hostname=self._check_hostname)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/urllib/request.py\", line 1319, in do_open\n",
      "    raise URLError(err)\n",
      "urllib.error.URLError: <urlopen error [Errno 101] Network is unreachable>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/threading.py\", line 917, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/threading.py\", line 865, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-23-061a4cf914d4>\", line 22, in finding_location\n",
      "    location=geolocator.geocode(address)\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/site-packages/geopy/geocoders/osm.py\", line 387, in geocode\n",
      "    self._call_geocoder(url, timeout=timeout), exactly_one\n",
      "  File \"/home/boo/miniconda3/envs/p/lib/python3.7/site-packages/geopy/geocoders/base.py\", line 380, in _call_geocoder\n",
      "    raise GeocoderUnavailable('Service not available')\n",
      "geopy.exc.GeocoderUnavailable: Service not available\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from threading import Thread\n",
    "\n",
    "total_thread=12\n",
    "delta=len(df)/total_thread\n",
    "\n",
    "thread_list=[]\n",
    "\n",
    "for thread_no in range(1,total_thread+1):\n",
    "    start_index=int((thread_no-1)*delta)\n",
    "    end_index=int(thread_no*delta)    \n",
    "    t=Thread(target=finding_location, args=(df,start_index, end_index,))\n",
    "    thread_list.append(t)\n",
    "\n",
    "for t in thread_list:\n",
    "    t.start()\n",
    "\n",
    "for t in thread_list:\n",
    "    t.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"nyc_tor_location.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------Checkpoint-----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"nyc_tor_location.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting Foursqure Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up Foursquare API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "CLIENT_ID = '0AN3UQMPGX1WAWOL30A4V32URKRUW40GEGWPAY4AOG5EXBAU'\n",
    "CLIENT_SECRET = 'XQVSEVB5BI35THZYUL1G1ZEC3YLNPR1NDMP3PM1XQPDINXTF' # your Foursquare Secret\n",
    "VERSION = '20180604'\n",
    "LIMIT = 30\n",
    "radius=500\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Latitude: 40.866111100000005 Longitude: -73.85055559999999\n"
     ]
    }
   ],
   "source": [
    "latitude=df.iloc[1][\"Latitude\"]\n",
    "longitude=df.iloc[1][\"Longitude\"]\n",
    "url='https://api.foursquare.com/v2/venues/search?client_id={}&client_secret={}&ll={},{}&v={}&radius={}'.format(CLIENT_ID, CLIENT_SECRET, latitude, longitude, VERSION,radius)\n",
    "print(\"For Latitude:\", latitude, \"Longitude:\", longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = requests.get(url).json()\n",
    "venues=results[\"response\"][\"venues\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=[\"Neighborhoods\",'Boroughs', 'City','Latitude',\n",
    "       'Longitude', \"Venue\",\"Category\",\"VenueLat\", \"VenueLong\"]\n",
    "df_venue=pd.DataFrame(columns=cols)\n",
    "\n",
    "\n",
    "Neighborhoods_list=[]\n",
    "Boroughs_list=[]\n",
    "City_list=[]\n",
    "Latitude_list=[]\n",
    "Longitude_list=[] \n",
    "Venue_list=[]\n",
    "Category_list=[]\n",
    "VenueLat_list=[] \n",
    "VenueLong_list=[]\n",
    "            \n",
    "def get_venues(latitude, longitude):\n",
    "    CLIENT_ID = '0AN3UQMPGX1WAWOL30A4V32URKRUW40GEGWPAY4AOG5EXBAU'\n",
    "    CLIENT_SECRET = 'XQVSEVB5BI35THZYUL1G1ZEC3YLNPR1NDMP3PM1XQPDINXTF' # your Foursquare Secret\n",
    "    VERSION = '20180604'\n",
    "    LIMIT = 30\n",
    "    radius=500\n",
    "    url='https://api.foursquare.com/v2/venues/search?client_id={}&client_secret={}&ll={},{}&v={}&radius={}'.format(CLIENT_ID, CLIENT_SECRET, latitude, longitude, VERSION,radius)\n",
    "    results= requests.get(url).json()\n",
    "    venues=results[\"response\"][\"venues\"]\n",
    "    return venues\n",
    "\n",
    "def get_venue_details(venue):\n",
    "    name=venue[\"name\"]\n",
    "    \n",
    "    try:\n",
    "        category=venue[\"categories\"][0][\"name\"]\n",
    "    except:\n",
    "        category=\"\"\n",
    "        \n",
    "    try:\n",
    "        lat=venue[\"location\"][\"lat\"]\n",
    "        long=venue[\"location\"][\"lng\"]\n",
    "    except:\n",
    "        lat=\"\"\n",
    "        long=\"\"\n",
    "    \n",
    "    return name, category, lat, long\n",
    "\n",
    "def df_venue_maker(df,start_index, end_index):\n",
    "    print(\"Start:\", start_index,\"End:\",end_index)\n",
    "    \n",
    "    for i in range(start_index, end_index):\n",
    "        neighbourhood=df.iloc[i][\"Neighborhoods\"]\n",
    "        borough=df.iloc[i][\"Boroughs\"]\n",
    "        city=df.iloc[i][\"City\"]\n",
    "        latitude=df.iloc[i][\"Latitude\"]\n",
    "        longitude=df.iloc[i][\"Longitude\"]\n",
    "#         print(\"For Index:\", i)\n",
    "#         print(neighbourhood,\", \",borough,\", \",city)\n",
    "        venues=get_venues(latitude, longitude)\n",
    "\n",
    "        for venue in venues:\n",
    "            v_name,category,v_lat,v_long=get_venue_details(venue)\n",
    "                \n",
    "            Neighborhoods_list.append(neighbourhood),\n",
    "            Boroughs_list.append(borough),\n",
    "            City_list.append(city),\n",
    "            Latitude_list.append(latitude),\n",
    "            Longitude_list.append(longitude), \n",
    "            Venue_list.append(v_name),\n",
    "            Category_list.append(category),\n",
    "            VenueLat_list.append(v_lat), \n",
    "            VenueLong_list.append(v_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Multi Threading for speeding up data retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "from threading import Thread\n",
    "import queue\n",
    "\n",
    "\n",
    "total_thread=12\n",
    "delta=len(df)/total_thread\n",
    "\n",
    "thread_list=[]\n",
    "\n",
    "for thread_no in range(1,total_thread+1):\n",
    "    start_index=int((thread_no-1)*delta)\n",
    "    end_index=int(thread_no*delta)\n",
    "    \n",
    "    t=Thread(target=df_venue_maker, args=(df,start_index, end_index,))\n",
    "    \n",
    "    thread_list.append(t)\n",
    "\n",
    "for t in thread_list:\n",
    "    t.start()\n",
    "\n",
    "for t in thread_list:\n",
    "    t.join()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attaching back all data into data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_dict={\n",
    "            \"Neighborhoods\":Neighborhoods_list,\n",
    "            \"Boroughs\":Boroughs_list,\n",
    "            \"City\":City_list,\n",
    "            \"Latitude\":Latitude_list,\n",
    "            \"Longitude\":Longitude_list, \n",
    "            \"Venue\":Venue_list,\n",
    "            \"Category\":Category_list,\n",
    "            \"VenueLat\":VenueLat_list, \n",
    "            \"VenueLong\":VenueLong_list, \n",
    "}\n",
    "df=pd.DataFrame(all_data_dict)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./nyc_tor_venue.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------Checkpoint-----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"./nyc_tor_venue.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Data for modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing rows with empty cells\n",
    "Empty cells in GPS coordinates of the neighborhood will not render in the map so we will delete such cell. \n",
    "Also, cells without a category will be useless for classification so must be deleted too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()\n",
    "df=df[~df[\"Category\"].isnull()]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No of different categories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[\"Category\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reducing number of categories or features set.\n",
    "We have 477 categories which is very large and redundant.\n",
    "One way to solve this issue is to push up the child categories to parent categories as it will prevent any data loss. \n",
    "We do this by finding the categories structure from foursquare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting category structure from foursquare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENT_ID = '0AN3UQMPGX1WAWOL30A4V32URKRUW40GEGWPAY4AOG5EXBAU'\n",
    "CLIENT_SECRET = 'XQVSEVB5BI35THZYUL1G1ZEC3YLNPR1NDMP3PM1XQPDINXTF' # your Foursquare Secret\n",
    "VERSION = '20180604'\n",
    "LIMIT = 30\n",
    "radius=500\n",
    "url='https://api.foursquare.com/v2/venues/categories?client_id={}&client_secret={}&v={}'.format(CLIENT_ID, CLIENT_SECRET,  VERSION)\n",
    "import requests\n",
    "results = requests.get(url).json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving category structure in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat=pd.DataFrame(columns=[\"1\",\"2\",\"3\",\"4\",\"5\"])\n",
    "\n",
    "for cat1 in results[\"response\"][\"categories\"]:\n",
    "    \n",
    "    row={\n",
    "        \"1\":\"\",\n",
    "        \"2\":\"\",\n",
    "        \"3\":\"\",\n",
    "        \"4\":\"\",\n",
    "        \"5\":\"\",\n",
    "    }\n",
    "    \n",
    "    cat1_name=cat1[\"name\"]\n",
    "    print(cat1_name)\n",
    "    \n",
    "    \n",
    "    row[\"1\"]=cat1_name\n",
    "    row[\"2\"]=\"\"\n",
    "    row[\"3\"]=\"\"\n",
    "    row[\"4\"]=\"\"\n",
    "    row[\"5\"]=\"\"\n",
    "    \n",
    "    cat=cat.append(row,ignore_index=True)\n",
    "    \n",
    "    if cat1[\"categories\"]:\n",
    "        for cat2 in cat1[\"categories\"]:\n",
    "            cat2_name=cat2[\"name\"]\n",
    "            print(\"|->\",cat2_name)\n",
    "            \n",
    "            \n",
    "            row[\"2\"]=cat2_name\n",
    "            row[\"3\"]=\"\"\n",
    "            row[\"4\"]=\"\"\n",
    "            row[\"5\"]=\"\"\n",
    "    \n",
    "            cat=cat.append(row,ignore_index=True)\n",
    "            \n",
    "            \n",
    "    \n",
    "            if cat2[\"categories\"]:\n",
    "                for cat3 in cat2[\"categories\"]:\n",
    "                    cat3_name=cat3[\"name\"]\n",
    "                    print(4*\" \"+\"|->\",cat3_name)\n",
    "                    \n",
    "                    row[\"3\"]=cat3_name\n",
    "                    row[\"4\"]=\"\"\n",
    "                    row[\"5\"]=\"\"\n",
    "    \n",
    "                    cat=cat.append(row,ignore_index=True)\n",
    "                    \n",
    "                    if cat3[\"categories\"]:\n",
    "                        for cat4 in cat3[\"categories\"]:\n",
    "                            cat4_name=cat4[\"name\"]\n",
    "                            print(8*\" \"+\"|->\",cat4_name)\n",
    "                            row[\"4\"]=cat4_name\n",
    "                            row[\"5\"]=\"\"\n",
    "                            \n",
    "                            cat=cat.append(row,ignore_index=True)\n",
    "                            \n",
    "                            if cat4[\"categories\"]:\n",
    "                                for cat5 in cat4[\"categories\"]:\n",
    "                                    cat5_name=cat5[\"name\"]\n",
    "                                    print(12*\" \"+\"|->\",cat5_name)\n",
    "                                    row[\"5\"]=cat5_name\n",
    "                                    cat=cat.append(row,ignore_index=True)\n",
    "cat.to_csv(\"categories.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how the category structure looks, where 1 represent 1st level category and 4 represent 4th level category.4th is of course child of 1st."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to classify child category to parent category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def child_to_parent(df, cat, level):\n",
    "    print(\"Coverting level:\",level,\"to\",level-1)\n",
    "    print(\"No of categoris in df\")\n",
    "    print(\"Before run:\", len(df[\"Category\"].unique()))\n",
    "    \n",
    "    for i in cat.index:\n",
    "        child_col=str(level)\n",
    "        parent_col=str(level-1)\n",
    "        \n",
    "        child_cat=cat.iloc[i][child_col]\n",
    "        parent_cat=cat.iloc[i][parent_col]\n",
    "        \n",
    "        if child_cat!=\"\":\n",
    "            \n",
    "            try:\n",
    "                for j in df[df[\"Category\"]==child_cat].index:\n",
    "                    df.at[j,\"Category\"]=parent_cat\n",
    "            except:\n",
    "                print(\"No common category found\")\n",
    "    \n",
    "    print(\"After run\",len(df[\"Category\"].unique()))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Level:5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "child_to_parent(df, cat, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Level:4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "child_to_parent(df, cat, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Level:3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "child_to_parent(df, cat, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Level:2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "child_to_parent(df, cat, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting Category column to one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hot=pd.get_dummies(data=df, columns=[\"Category\"], prefix_sep=\"\",prefix=\"\")\n",
    "df_hot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping data based on Neighborhoods and City."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hot_grouped=df_hot.groupby([\"Neighborhoods\",\"City\",\"Latitude\",\"Longitude\"]).mean().reset_index()\n",
    "df_hot_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retriving X from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_hot_grouped[df_hot_grouped.columns[6:]]\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describing Data\n",
    "It would have been completely vain, had we described the data without even retrieving them first. Now that we already have the data we can easily describe them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Describing data's X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_str=\"\"\n",
    "for col in X.columns:\n",
    "    col_str=col_str+\" | \"+str(col)\n",
    "print(\"Categories are\")\n",
    "print(col_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Describing data's y\n",
    "\n",
    "Since we do not have labeled data we will use unsupervised learning and hence we do not have any dependent variable y as it will be decided by model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding correlation between feature sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "sns.heatmap(X.corr(), annot=True, cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A good thing to note is that we do not have any correlation among our feature set, so we can easily proceed further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding box plot of data's X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=df[[\"Category\",\"Neighborhoods\",\"Venue\"]].groupby([\"Category\",\"Neighborhoods\"]).count()\n",
    "z=pd.DataFrame(z)\n",
    "z=z.reset_index()\n",
    "z.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart=sns.catplot(x=\"Category\", y=\"Venue\", kind=\"box\", data=z, palette=\"bright\",height=8.27, aspect=11.7/8.2)\n",
    "\n",
    "for ax in chart.axes.flat:\n",
    "    for label in ax.get_xticklabels():\n",
    "        label.set_rotation(90)\n",
    "plt.show(chart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We notice that venues like Food and Shops are more present than other category, this could have been due to particular city having more number of such venues, but since we do not know in certain we try to find this by making bar plot city wise and item wise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### City wise no of venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(y=\"Category\", hue=\"City\", kind=\"count\",\n",
    "            palette=\"colorblind\", edgecolor=\".2\",\n",
    "            data=df, height=8.27, aspect=11.7/8.2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The most interesting part of this graph is that for both cities on total level the composition of venues are similar.So our previous hypothesis that a particular city might be having more number of shop and food in compostion is rejected.  \n",
    "* Also in every venue category Ney York has almost the double the amount of venues compared to that of Toronto, but the compostion is alomost similar. Which we can clarify using pie chart of both this city sepeartly side by side. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### City wise venues composition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tor=df[df[\"City\"]==\"TOR\"][\"Category\"].value_counts()\n",
    "tor_labels = df_tor.index\n",
    "tor_sizes = df_tor.values\n",
    "\n",
    "df_nyc=df[df[\"City\"]==\"NYC\"][\"Category\"].value_counts()\n",
    "nyc_labels = df_tor.index\n",
    "nyc_sizes = df_tor.values\n",
    "\n",
    "\n",
    "explode = (0, 0.1, 0, 0, 0, 0, 0, 0,0,0)  \n",
    "colors=sns.color_palette(\"colorblind\",10).as_hex()\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,15))\n",
    "fig.figsize=(20,20)\n",
    "\n",
    "ax1.pie(tor_sizes, explode=explode, labels=tor_labels, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90, rotatelabels=True, colors=colors)\n",
    "\n",
    "ax2.pie(nyc_sizes, explode=explode, labels=nyc_labels, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90, rotatelabels=True, colors=colors)\n",
    "\n",
    "ax1.set_title(\"Toronto\", fontsize=16)\n",
    "ax2.set_title(\"New York\", fontsize=16)\n",
    "\n",
    "ax1.axis('equal')\n",
    "ax2.axis('equal')\n",
    "# plt.pie(tor_sizes, explode=explode, labels=tor_labels, autopct='%1.1f%%',\n",
    "#         shadow=True, startangle=90, rotatelabels=True, )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We notice that with every venue the compostion of venue has remained same in cities although New York have double the amount of venue. \n",
    "* Thus our techniques of scoring by the method of recommeder system will never yield more than 50% of similarity as New York will always be twice denser than new Toronto. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing Technique\n",
    "There are two ways for us to solve the issue of classification:\n",
    "1. K-Means: Because we have unlabeled data and we can form cluster. But since we have 417 column or features set with many empty columns, the eculudian distance will always be very less and thus many places will will be miss classified. \n",
    "\n",
    "2. Recommender System: While it may be argued that we do not have ratings of places, then how do we use recommeder system. This issue can easily be mitigated because sum of similar venues in particular neighbhoirhood represent the composition of particualt neighbhourhood, hence we have already have a wighted genre/type of venue with us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Technique\n",
    "#### Normalization\n",
    "The problem with our data is that while some neighbhorhood may have more venues other may have, what we seek is thier underlying compostion so we normalize the the rows.\n",
    "#### Multiplication\n",
    "Now we mulyiply the normalized row to the dataframe.\n",
    "#### Finding top 10 neighbhorhood\n",
    "Now we sum up all the columns row wise to obtain row score, and find the 10 places with highest score. \n",
    "\n",
    "All the above steps are done with the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_10(X,i):\n",
    "    Xc=X.iloc[i]\n",
    "#     Xc=Xc/Xc.sum(axis=0)\n",
    "    Xm=X.mul(Xc, axis=1)\n",
    "    top_10=Xm.sum(axis=1).sort_values(ascending=False)[1:11]\n",
    "    return top_10\n",
    "\n",
    "get_top_10(X,2) #Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding top 10 Venue by numbers in neighbhorhood  \n",
    "Here we use number to represent the for venue in neighbhorhood. \n",
    "Ex. Thus 3 represent 3rd most present venue in neighbhorhood. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt={}\n",
    "def update_top_10_venue_in_neighbhoorhood(X,j,dt):\n",
    "    dt_slice=X.iloc[j].sort_values(ascending=False)[:10]\n",
    "    for i, index, value in zip(range(1,11),dt_slice.index, dt_slice.values):\n",
    "        dt[str(i)]=index\n",
    "        dt[str(i)+\"v\"]=value\n",
    "        \n",
    "    return dt\n",
    "update_top_10_venue_in_neighbhoorhood(X,10,dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looping through all the places and looping again for top 10 similar places to save into data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Easioer to use short name\n",
    "dfx=df_hot_grouped\n",
    "\n",
    "row_list=[]\n",
    "\n",
    "for i in dfx.index:\n",
    "# for i in range(1,2):\n",
    "    neighborhood=dfx.iloc[i][\"Neighborhoods\"]\n",
    "    city=dfx.iloc[i][\"City\"]\n",
    "    latitude=dfx.iloc[i][\"Latitude\"]\n",
    "    longitude=dfx.iloc[i][\"Longitude\"]\n",
    "    \n",
    "    top_10=get_top_10(X,i)\n",
    "    \n",
    "    rank=0\n",
    "    \n",
    "    for j, score in zip(top_10.index,top_10.values):\n",
    "        m_neighborhood=dfx.iloc[j][\"Neighborhoods\"]\n",
    "        m_city=dfx.iloc[j][\"City\"]\n",
    "        m_latitude=dfx.iloc[j][\"Latitude\"]\n",
    "        m_longitude=dfx.iloc[j][\"Longitude\"]\n",
    "        rank+=1\n",
    "        score=score\n",
    "        \n",
    "        \n",
    "        row={\"neighborhood\":neighborhood, \n",
    "        \"city\":city, \n",
    "        \"latitude\":latitude, \n",
    "        \"longitude\":longitude, \n",
    "        \"m_neighborhood\":m_neighborhood,\n",
    "        \"m_city\":m_city, \n",
    "        \"m_latitude\":m_latitude, \n",
    "        \"m_longitude\":m_longitude, \n",
    "        \"rank\":rank,\n",
    "        \"score\":score,  \n",
    "        }\n",
    "        row=update_top_10_venue_in_neighbhoorhood(X,j,row)\n",
    "        \n",
    "        \n",
    "        row_list.append(row)\n",
    "    \n",
    "dfy=pd.DataFrame(row_list)\n",
    "dfy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfy.index.name=\"Id\"\n",
    "dfy.to_csv(\"nyc_tor_y.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------Checkpoint-----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfy=pd.read_csv(\"nyc_tor_y.csv\", index_col=\"Id\")\n",
    "dfy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The location cordinates will be used to create presentation in tableu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Plot of score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we must find how good our technique is and so we create a normal graph for our score. We expect that it must be near or less than 0.5  as in our EDA section we have made it clear that New York is twice as dense as Toronto. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "sns.distplot(dfy[\"score\"], bins=40)  \n",
    "\n",
    "colors=sns.color_palette(\"colorblind\",10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed our normal plot have more values are between 0.1 and 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be verified by mean and standard deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfy[\"score\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfy[\"score\"].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a recomender retreival function.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommedation():\n",
    "    n=str(input(\"Which Neighborhood do you live in ?: \")).lower()\n",
    "    cols=['m_neighborhood','m_city', 'm_latitude', 'm_longitude', 'rank', 'score']\n",
    "    y=dfy.loc[dfy[\"neighborhood\"].str.lower()==n,cols]\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recommedation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tableau Presentation\n",
    "But since this method of getting recommendation is not very interavtive, we will preapare a tabeleau dashboard to accomplish our goal.\n",
    "In order to make tabeleau dashboard we will now have to make dataframes so that it can easily be fed to tableau."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making dataframe for arrows file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arrow=pd.DataFrame(columns=[\"Origin_Destination\",\"Neighborhood\",\"Id\",\"Latitude\",\"Longitude\"])\n",
    "\n",
    "for i in dfy.index:\n",
    "    origin_dict={\n",
    "    \"Origin_Destination\":\"Origin\",\n",
    "    \"Neighborhood\":dfy.iloc[i][\"neighborhood\"],\n",
    "    \"Id\":i,\n",
    "    \"Latitude\":dfy.iloc[i][\"latitude\"],\n",
    "    \"Longitude\":dfy.iloc[i][\"longitude\"],\n",
    "    }\n",
    "    destination_dict={\n",
    "    \"Origin_Destination\":\"Destination\",\n",
    "    \"Neighborhood\":dfy.iloc[i][\"m_neighborhood\"],\n",
    "    \"Id\":i,\n",
    "    \"Latitude\":dfy.iloc[i][\"m_latitude\"],\n",
    "    \"Longitude\":dfy.iloc[i][\"m_longitude\"],\n",
    "    }\n",
    "    \n",
    "    df_arrow=df_arrow.append(origin_dict, ignore_index=True)\n",
    "    df_arrow=df_arrow.append(destination_dict,ignore_index=True)\n",
    "    \n",
    "df_arrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arrow.to_csv(\"arrow.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------Checkpoint-----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making data frame for top 10 venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_venue=pd.DataFrame(columns=[\"Id\",\"Venue\",\"Score\",\"Rank\"])\n",
    "\n",
    "for i in dfy.index:\n",
    "    \n",
    "    for j in range(1,11):\n",
    "        venue_col=str(j)\n",
    "        score_col=str(j)+\"v\"\n",
    "        \n",
    "        venue_dict={\n",
    "        \"Id\":i,\n",
    "        \"Venue\":dfy.iloc[i][venue_col],\n",
    "        \"Score\":dfy.iloc[i][score_col],\n",
    "        \"Rank\":dfy.iloc[i][\"rank\"],\n",
    "        }\n",
    "    \n",
    "        df_venue=df_venue.append(venue_dict, ignore_index=True)\n",
    "    \n",
    "df_venue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_venue.to_csv(\"venues.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------Checkpoint-----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tableau Dashboard Link:  https://sagarrathi.github.io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion & Recomendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that our recommendation system is unable to yield a score above 0.5, the reason for which was found by performing EDA analysis. EDA analysis proved that New York and Toronto have similar composition of venues but New York has almost twice the amount of venues than that of Toronto.\n",
    "While we were about to choose K-means clustering, the algorithm would have stripped away various essentail data as we see in recommendation system that we have top 10 neighbhoord suggestion with score ranging form 0.48 to 0.1. The amount of similarity which we gain in recommendation system would have been not present in case of K-means clustering. \n",
    "For every Neighbhouurhood not only do we recommend top 10 similar neighbhoord but also the features or venue composition along with their ranking and score.\n",
    "We could have easily just multiplied the the results of Toronto by 2 to compensate for the density but we are not doing it as it may cause data loss.\n",
    "A better Neural Network technique could have been used because we had 477 Categories label for venue  but sicne we have only 181 Neighbhouurhood data points it would have been a wrong choice. Hence the 477 Categories label were merged to form only 10 categories label. May be in future by having large number of dataset we can easily use neural network.\n",
    "The most fundamental problem in our project was that we did not include population density and other economic parameters for the reason that we only focused on comparing places based on their venue compositon structure. Using other economic parameter would have been a another project altogether. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conculsion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we learn from this project is that recomednation system can also be used for unlabeled data, which we have performed successfully in this project. \n",
    "A better way to conclude this report would have been to make a Tableau Story which can easily suggest places to people looking for new place to live. The link of which can be found here:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "312.997px",
    "left": "1487.28px",
    "top": "300.284px",
    "width": "258.168px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
